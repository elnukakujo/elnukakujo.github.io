[
    {
        "anchorId": "my_memory_chat",
        "title": "My Memory Chat: A LLM Chatbot for Memory Recall",
        "tags": ["graph_rag", "generative_agents", "llm", "langchain", "neo4j", "flask", "react", "js", "full_stack", "prompt_eng", "gemini", "py", "figma", "api", "soft_eng", "ux_design"],
        "summary": "A client-server application integrating Gemini, Neo4j knowledge graphs, and the ReAct (Reason + Act) prompting method, allowing users to interact with an LLM to store life events and entities in a memory graph and receive insightful responses.",
        "description": {
            "context":"As digital interactions become more integrated into daily life, there is a growing need for AI assistants that can engage in **meaningful, long-term conversations while managing personal information securely**. Users want a system that not only remembers **key details** about their private lives—such as **people**, **events**, and **preferences**—but also **retrieves related images** to enhance interactions. However, ensuring data persistence, accessibility, and security remains a challenge. A robust memory system **must prevent data loss**, allow seamless external database access, and maintain user trust through reliable and structured information storage.",
            "problem":"How can a **conversational AI assistant** effectively **store, retrieve, and manage user-specific personal information**, including images, while **ensuring data persistence, security, and seamless accessibility** across external databases?",
            "contribution":"This project introduces a **full-stack conversational assistant** designed to address these challenges by integrating **Gemini 1.5**, a **Neo4j knowledge graph**, and **LLM Agents** for efficient long-term memory management. The system features a **React frontend and a Flask backend**, enabling smooth and responsive user interactions. To enhance reliability, it includes an **automated Neo4j backup system**, ensuring data persistence and protection against loss. Additionally, the app supports **image retrieval**, allowing users to associate images with their stored knowledge for a richer conversational experience. **Performance is optimized with quick response times (5-8 seconds)** and a **request-locking mechanism** to prevent simultaneous conflicting queries, ensuring a seamless and efficient user experience."
        },
        "date": "February - March 2025",
        "githubUrl": "https://github.com/MyMemoryChat",
        "images": [
            {
                "imageUrl": "https://raw.githubusercontent.com/MyMemoryChat/LLM_agent/main/neo4jconsole.png",
                "description": "Image of the Neo4j console with the memory graph"
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/MyMemoryChat/Client/refs/heads/main/images/ExampleConversation2.png",
                "description": "Example history of a conversation in the React client"
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/MyMemoryChat/Client/refs/heads/main/images/ExampleImageDisplay.png",
                "description": "Example image informations display in the React client"
            }
        ],
        "external_ref": [
            {
                "title": "Gemini 1.5",
                "url": "https://aistudio.google.com/welcome?gclsrc=aw.ds&gad_source=1&gclid=Cj0KCQjwhYS_BhD2ARIsAJTMMQbEn7bJ0G52fWdF0NZPnlr-Ggw70ZxUIvn1MUpzdY7tkSBwnjQmeRYaAk_DEALw_wcB"
            },
            {
                "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
                "url": "https://arxiv.org/abs/2210.03629"
            },
            {
                "title": "GraphRAG: Unlocking LLM discovery on narrative private data ",
                "url": "https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/"
            }
        ],
        "featured": true
    },
    {
        "anchorId": "my_family_story",
        "title": "Generative Agents for Large Language Model Family Story Generation",
        "tags": ["generative_agents", "graph_rag", "llm", "langchain", "neo4j", "prompt_eng", "gemini", "py"],
        "summary": "Leveraging advancements in Retrieval-Augmented Generation (RAG) and Generative Agents, this application stores family images and comments in a knowledge graph to generate a personalized family storybook.",
        "description": "This project leverages Retrieval-Augmented Generation (RAG) and Generative Agents to create a personalized family storybook enriched with both text and visuals. A Neo4j knowledge graph stores family images, memories, and comments, allowing an LLM-powered agent to generate dynamic, context-aware narratives that reflect personal histories and relationships. Additionally, a dedicated image-selection agent explores the graph to retrieve relevant photos for each generated paragraph, ensuring meaningful visual storytelling. The final output is automatically formatted and converted into a Word document, providing a beautifully structured, shareable family album that brings memories to life in a seamless, AI-assisted storytelling experience.",
        "date": "January - February 2025"
    },
    {
        "anchorId": "summoner_insight",
        "title": "Summoner-Insight: Real-Time Visualization and Prediction Assistant",
        "tags": ["react", "full_stack", "transformer", "huggingface", "js", "redux", "api", "soft_eng", "dotnet", "cs", "devops", "ux_design"],
        "summary": "A real-time visualization and prediction assistant for League of Legends, leveraging Deep Learning models for highly accurate recommendations and predictions, combined with D3.js for dynamic visualizations.",
        "description": {
            "context":"In League of Legends, players must process large amounts of information in real time to make strategic decisions. However, understanding game dynamics, predicting outcomes, and identifying optimal plays can be overwhelming, especially given the complexity of team compositions, item choices, and in-game events. Traditional analytics tools offer post-game statistics but often fail to provide actionable insights during gameplay. At the same time, recent advancements in Deep Learning, particularly Transformer-based models, have significantly improved the ability to process and interpret sequential data. These models excel at capturing long-range dependencies and contextual patterns, making them well-suited for analyzing evolving game states and predicting future scenarios with high accuracy.",
            "problem":"How can real-time analysis and prediction in League of Legends be improved using Transformer-based models to process complex game states and provide actionable insights during gameplay with a high degree of certainty?"},
        "date": "June 2024 - In Progress",
        "githubUrl": "https://github.com/AnalyticsLoL/SummonerInsight",
        "videoUrl": "https://www.youtube.com/embed/ZksTQdx19MU?si=YGJKUTVtG4t4aUyP",
        "websiteUrl": "http://dev.summonerinsight.com/",
        "progress": {
            "phase": "implementation",
            "status_infos": "- Basic UI designed with visualization tools and user profiles. \n - Backend API with connection to Riot API done.\n - Previous deployed but currently down due to a hardware problem.\n - Working on training a win prediction model using only start of the game players information."
        },
        "featured": true
    },
    {
        "anchorId": "math_storytelling_llm_human_comparative_study",
        "title": "Empirical Study on Teaching Math through Storytelling",
        "tags": ["empirical_methods", "mixed_methods", "aws_elastic_beanstalk", "aws_cloudfront", "aws_amplify", "r", "llm", "hci", "js", "react", "cs", "dotnet"],
        "date": "September - December 2024",
        "summary":"A final project for IFT6075: Empirical Methods in Human-Computer Interaction at the Université de Montréal, inspired by the CHI 2024 paper Mathemyths. This study compares the effectiveness of teaching advanced math concepts through storytelling by human professors versus Large Language Models (LLMs) (ChatGPT, LLaMA 3.2-3B-Instruct). Data from 16 participants was collected using a Graeco-Latin square design, with each participant exposed to stories from both sources. Analysis was conducted using Linear Models in R.",
        "descriptions": [
            "IFT6075 Empirical Methods in Human-Computer Interaction Final Project at University of Montreal",
            "Based on the research from the CHI 2024 conference article 'Mathemyths: Leveraging Large Language Models to Teach Mathematical Language through Child-AI Co-Creative Storytelling'",
            "Comparison of the effectiveness of teaching advanced math concepts to university students through storytelling between human teachers and Large Language Models",
            "The stories are either written by maths professors from the University of Montreal or generated by an Large Language Model application (ChatGPT, or LLama3.2-3B-Instruct)",
            "The data is collected from 16 participants using a graeco latin square design, with 1 story from each source",
            "The data is analyzed with Linear Models in a R notebook"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "pdfLink":{
            "project report":"https://raw.githubusercontent.com/elnukakujo/elnukakujo.github.io/main/mywebsite/src/assets/docs/IFT6075Report.pdf"
        },
        "githubUrl": "https://github.com/elnukakujo/Large Language Model_maths_storytelling/tree/main"
    },
    {
        "anchorId": "openai_assistant_m2_gen",
        "title": "Model assistant for the design of meta-models using OpenAI API",
        "tags": ["mde", "prompt_eng", "openai", "api", "soft_eng", "py", "pd", "llm"],
        "date": "September - December 2024",
        "summary": "A final project for IFT6253: Model-Driven Engineering at the Université de Montréal, inspired by the paper Automated Domain Modeling with Large Language Models: A Comparative Study. Developed a Modeling Assistant to aid designers in creating metamodels for Domain-Specific Languages, utilizing techniques such as Few-Shot learning, Partial Solution Models, and Task Generation. The application automatically converts models from a custom JSON architecture into Ecore files, with EMF Compare in Eclipse used for validation against expected metamodels.",
        "descriptions": [
            "IFT6253 Model-Driven Engineering final project at University of Montreal",
            "Using the Prompts and Model Evaluation methods, as well as metamodels descriptions and solutions from the paper 'Automated Domain Modeling with Large Language Models: A Comparative Study'",
            "Creating a Modeling Assistant to help designers create meta-models for Domain Specific Languages, using methods such as FewShot, a Partial Solution Model given to the model, and Task Generation",
            "Additionally, the application automatically converts the models saved as custom json architecture into ecore files and then I used EMF Compare in Eclipse to compare the generated metamodels with the expected ones."
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "githubUrl": "https://github.com/elnukakujo/OpenAI_Assistant_M2_Gen",
        "pdfLink":{
            "project report":"https://raw.githubusercontent.com/elnukakujo/elnukakujo.github.io/main/mywebsite/src/assets/docs/IFT6253Report.pdf"
        }
    },
    {
        "anchorId": "sign_language_recognition",
        "title": "Sign Language Recognition with Deep Neural Network using basic TensorFlow",
        "tags": ["py", "tf", "deepl", "cnn", "cv2", "plotly"],
        "date": "August 2024",
        "summary": "Built a TensorFlow Neural Network to recognize ASL letters from the Sign Language MNIST dataset, using OpenCV preprocessing and fully connected layers. Designed pipelines for hyperparameter tuning and optimization.",
        "descriptions": [
            "Implementing a Neural Network using TensorFlow to recognize the American Sign Language",
            "The dataset used is the Sign Language MNIST from Kaggle containing 24 letters (excluding J and Z)",
            "Used OpenCV to preprocess the images and TensorFlow (not Keras) to do the computations for a very basic model (No CNN only 'dense layers')",
            "The best hyperparameters are a learning rate starting from 6.5e-6 decaying manually to 5e-7, a mini batch size of 2**9 (512), two hidden layers with each 85 and 84 nodes, and a l2 lambda of 0 (not enough time to do the tuning for it but was still implemented)",
            "I created two pipelines for hypertuning with respective graphs: panda and caviar tuning (See the graphs below and the github for more info)",
            "The model has a 81% training accuracy, 65% testing accuracy and a 0.67 cost which is a good achievement for such a simple model"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "githubUrl": "https://github.com/elnukakujo/sign_language_recognition",
        "images": [
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/sign_language_recognition/main/data/plots/20240816_172458.png",
                "description": "The evolution curve of my best training model"
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/sign_language_recognition/main/data/plots/example_caviar_tuning.png",
                "description": "Example of a caviar tuning plot"
            }
        ],
        "featured": true
    },
    {
        "anchorId": "clothing_classification",
        "title": "Clothing classification Shallow Neural Networks with NumPy",
        "tags": ["py", "np", "deepl"],
        "date": "August 2024",
        "summary":"Developed shallow neural networks in Python with NumPy to classify clothing images from the Fashion MNIST dataset. Implemented a single-layer network for binary classification and a three-layer network using ReLU, Softmax, and mini-batch gradient descent, with an optimized version using Adam.",
        "descriptions": [
            "Implemented shallow neural networks in Python with NumPy to classify clothing images",
            "Used the Fashion MNIST dataset to train and test the model",
            "Two neural networks created:",
            "A single layer neural network, mimicking a logistic regression gradient descent for binary classification. Metrics after 2000 steps: 97% training/testing accuracy for tshirts and trousers and 0.075 cost",
            "A 3 layer neural network, using ReLU and Softmax activation functions, and mini batch gradient descent to classify 10 classes. Metrics after 10 epochs: 85% training accuracy, 83% testing accuracy and 0.45 cost",
            "The same 3 layer neural network, but using the adam optimizer to classify the 10 classes. Metrics after 10 epochs: 90% training accuracy, 87% testing accuracy and 0.27 cost"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "githubUrl": "https://github.com/elnukakujo/clothing_classification",
        "images": [
        {
            "imageUrl": "https://raw.githubusercontent.com/elnukakujo/clothing_classification/main/plot/binary/step_2000_train_acc_0.98.png",
            "description": "The binary classification training evolution curve"
        },
        {
            "imageUrl": "https://raw.githubusercontent.com/elnukakujo/clothing_classification/main/plot/multi_class/epoch_10_optimizer_none.png",
            "description": "The mini batch gradient descent for the multi classification"
        },
        {
            "imageUrl": "https://raw.githubusercontent.com/elnukakujo/clothing_classification/main/plot/multi_class/epoch_10_optimizer_adam.png",
            "description": "The mini batch gradient descent with Adam optimizer for the multi classification"
        }
        ]
    },
    {
        "anchorId": "movie_search_app",
        "title": "Movie search app",
        "tags": ["cs", "dotnet", "js", "react", "full_stack", "api", "soft_eng"],
        "date": "July 2024",
        "summary":"Developed a local movie search app with a React frontend and a .NET backend, integrating data from the TMDB API. Features include recommendations, search, movie and actor pages, ratings, and comments. A great learning experience in React and .NET development.",
        "descriptions": [
            "Created a local movie search app with a React frontend and a .Net backend",
            "Result has a lot of options: main page with recommendations, search page, movie/series page, actors page, commentaries and ratings",
            "All the data used on the website is collected from the TMDB API",
            "I could polish it more like filtering the comments and movie data, adding more movies on the home page too, but I feel like I did enough for now",
            "I had a fun time exploring React and .Net with this project"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "githubUrl": "https://github.com/elnukakujo/movieSearchApp",
        "videoUrl": "https://www.youtube.com/embed/4F4O1xsQ4WU?si=7nBexlFtNQ4BTcMg"
    },
    {
        "anchorId": "sportsai_website",
        "title": "Soccer coaching with SportsAI",
        "tags": ["plotly", "dash", "flask", "css", "data_viz", "py"],
        "date": "May - June 2024",
        "summary": "Final project for the INF8808E: Data Visualization course at Polytechnique Montréal, using a dataset from the 2020 Euro Cup. Developed a web application for soccer coaches to analyze and enhance player performance for SportsAI.",
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "githubUrl": "https://github.com/elnukakujo/INF8808_DataViz_SportsAIProject",
        "websiteUrl": "https://sportsaiproject.onrender.com/",
        "images": [
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/INF8808_DataViz_SportsAIProject/main/plots/italyperformance.png",
                "description": "Stacked bar charts showcasing Italy's performance in Euro 2020 across various metrics, with an added layer indicating their positions."
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/INF8808_DataViz_SportsAIProject/main/plots/radarchart.png",
                "description": "Radar Chart comparing Italy and England's performance in Euro 2020 across various metrics."
            }
        ],
        "featured": true
    },
    {
        "anchorId": "drawing_with_webcam",
        "title": "Drawing with a webcam",
        "tags": ["py", "cv2", "comp_viz", "mediapipe"],
        "date": "February - June 2022",
        "summary": "Developed a real-time drawing application using Python and OpenCV under the guidance of Prof. Dr. Luis A. Leiva at the University of Luxembourg, leveraging finger position analysis for drawing actions.",
        "descriptions": [
            "With the tutoring of Prof. Dr. Luis A. LEIVA at University of Luxembourg",
            "Developed a real-time drawing application using Python and openCV",
            "Analyzed finger positions to determine drawing actions"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "githubUrl": "https://github.com/elnukakujo/BSP06-Drawing-with-a-webcam"
    },
    {
        "anchorId": "privacy_app_figma",
        "title": "Design of a privacy app with Figma",
        "tags": ["figma", "hci"],
        "summary": "A figma prototype of an IOS privacy app, designed in the context of my HCI bachelor course at the University of Luxembourg.",
        "date": "September - December 2021",
        "videoUrl": "https://www.youtube.com/embed/QCm1njo0ayM?si=wlDq4pp-bgf6woDg",
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        }
    },
    {
        "anchorId": "handwriting_generator",
        "title": "Handwriting Recognition with Tensorflow",
        "tags": ["deepl", "cnn", "tf", "py"],
        "date": "September 2021 - January 2022",
        "summary":"Developed a Convolutional Neural Network (CNN) in Python with TensorFlow to recognize diverse handwriting styles under the guidance of Prof. Dr. Luis A. Leiva at the University of Luxembourg, using a dataset from a separate project.",
        "descriptions": [
            "With the tutoring of Prof. Dr. Luis A. LEIVA at University of Luxembourg",
            "Implemented a Convolutional Neural Network in Python with TensorFlow to recognize from diverse handwriting",
            "Replicated various handwriting styles using a dataset from a separate project"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        }
    },
    {
        "anchorId": "chatbot",
        "title": "Conversational Chatbot with Tensorflow",
        "tags": ["deepl", "transformer", "tf", "py"],
        "date": "February - June 2021",
        "summary": "Developed a Transformer-based chatbot in Python with TensorFlow  at the University of Luxembourg. The model, featuring encoding, Bahdanau attention, and decoding, was trained on Reddit threads for French-English translation and small talk. The project included data extraction, cleaning, model training, and chatbot interface development.",
        "descriptions": [
            "With the tutoring of Prof Dr Christoph Schommer at University of Luxembourg",
            "Created a transformer architecture in Python with the TensorFlow library",
            "Data extraction, cleaning, online article research, definition of a model, its training, then creation of the Chatbot interface",
            "The model had 3 parts: encoding, Attention layer, and decoding",
            "Reddit threads with parent commentaries as a dataset between French and English and engages in small talk"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        }
    },
    {
        "anchorId": "q_learning_drone",
        "title": "Q Learning for a drone in a simulated environment",
        "tags": ["q_learning", "py", "robot"],
        "date": "September 2020 - January 2021",
        "summary": "Under the guidance of Dr. Jose Luis Sanchez Lopez at the University of Luxembourg, trained a drone to navigate and avoid obstacles in a simulated AirSim environment using Python and Q-learning with a defined Q-table and rewards.",
        "descriptions": [
            "With the tutoring of Dr Jose Luis Sanchez Lopez at University of Luxembourg",
            "Trained a drone to navigate while avoiding obstacles in a simulated environment (airsim) using Python",
            "Q-learning with a defined Q table and rewards"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        }
    },
    {
        "anchorId": "group_drone",
        "title": "Control of a group of drone with Unreal Engine 4 using Python",
        "tags": ["py", "ue4", "robot"],
        "date": "February - June 2020",
        "summary": "Under the guidance of Dr. Grégoire Danoy at the University of Luxembourg, developed a simulated quadrotor environment in Unreal Engine 4 with Python, enabling drones to navigate, avoid obstacles, and prevent collisions using linear algebra-based movement control.",
        "descriptions": [
            "With the tutoring of Dr Gregoire Danoy at University of Luxembourg to create a simulated environment with quadrotors as agents",
            "Controlled drones to avoid obstacles and collisions using Unreal Engine 4 and Python",
            "Applied linear algebra concepts for precise drone movements"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        },
        "videoUrl": "https://www.youtube.com/embed/V8-CfdUBPYI?si=k667HmWQLU5A2UTB"
    },
    {
        "anchorId": "sparki",
        "title": "Chase with Sparki",
        "tags": ["arduino", "robot"],
        "date": "September 2019 - January 2020",
        "summary": "Under the guidance of Dr. Grégoire Danoy at the University of Luxembourg, programmed Sparki robots in Sparkiduino to chase another Sparki while staying within an enclosure marked on the ground.",
        "descriptions": [
            "With the tutoring of Dr Gregoire Danoy at University of Luxembourg, learned about Sparki",
            "Coded Sparki in Sparkiduino to chase another Sparki",
            "They also needed to remain in an enclosure delimited by markers on the ground"
        ],
        "description": {
            "context":"",
            "problem":"",
            "contribution":""
        }
    }
]