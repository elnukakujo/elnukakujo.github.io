[
    {
        "anchorId": "my_memory_chat",
        "title": "My Memory Chat: A LLM Chatbot for Memory Recall",
        "tags": ["graph_rag", "generative_agents", "llm", "langchain", "neo4j", "flask", "react", "js", "full_stack", "prompt_eng", "gemini", "py", "figma", "api", "soft_eng", "ux_design"],
        "summary": "A client-server application integrating Gemini, Neo4j knowledge graphs, and the ReAct (Reason + Act) prompting method, allowing users to interact with an LLM to store life events and entities in a memory graph and receive insightful responses.",
        "description": {
            "context":"As digital interactions become more integrated into daily life, there is a growing need for AI assistants that can engage in **meaningful, long-term conversations while managing personal information securely**. Users want a system that not only remembers **key details** about their private lives—such as **people**, **events**, and **preferences**—but also **retrieves related images** to enhance interactions. However, ensuring data persistence, accessibility, and security remains a challenge. A robust memory system **must prevent data loss**, allow seamless external database access, and maintain user trust through reliable and structured information storage.",
            "problem":"*How can a **conversational AI assistant** effectively **store, retrieve, and manage user-specific personal information**, including images, while **ensuring data persistence, security, and seamless accessibility** across external databases?*",
            "contribution":"This project introduces a **full-stack conversational assistant** designed to address these challenges by integrating **Gemini 1.5**, a **Neo4j knowledge graph**, and **LLM Agents** for efficient long-term memory management. The system features a **React frontend and a Flask backend**, enabling smooth and responsive user interactions. To enhance reliability, it includes an **automated Neo4j backup system**, ensuring data persistence and protection against loss. Additionally, the app supports **image retrieval**, allowing users to associate images with their stored knowledge for a richer conversational experience. **Performance is optimized with quick response times (5-8 seconds)** and a **request-locking mechanism** to prevent simultaneous conflicting queries, ensuring a seamless and efficient user experience."
        },
        "date": "February - March 2025",
        "githubUrl": "https://github.com/MyMemoryChat",
        "images": [
            {
                "imageUrl": "https://raw.githubusercontent.com/MyMemoryChat/LLM_agent/main/neo4jconsole.png",
                "description": "Image of the Neo4j console with the memory graph"
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/MyMemoryChat/Client/refs/heads/main/images/ExampleConversation2.png",
                "description": "Example history of a conversation in the React client"
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/MyMemoryChat/Client/refs/heads/main/images/ExampleImageDisplay.png",
                "description": "Example image informations display in the React client"
            }
        ],
        "external_ref": [
            {
                "title": "Gemini 1.5",
                "url": "https://aistudio.google.com/welcome?gclsrc=aw.ds&gad_source=1&gclid=Cj0KCQjwhYS_BhD2ARIsAJTMMQbEn7bJ0G52fWdF0NZPnlr-Ggw70ZxUIvn1MUpzdY7tkSBwnjQmeRYaAk_DEALw_wcB"
            },
            {
                "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
                "url": "https://arxiv.org/abs/2210.03629"
            },
            {
                "title": "GraphRAG: Unlocking LLM discovery on narrative private data ",
                "url": "https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/"
            }
        ],
        "featured": true
    },
    {
        "anchorId": "my_family_story",
        "title": "Generative Agents for Large Language Model Family Story Generation",
        "tags": ["generative_agents", "graph_rag", "llm", "langchain", "neo4j", "prompt_eng", "gemini", "py"],
        "summary": "Leveraging advancements in Retrieval-Augmented Generation (RAG) and Generative Agents, this application stores family images and comments in a knowledge graph to generate a personalized family storybook.",
        "description": "This project leverages Retrieval-Augmented Generation (RAG) and Generative Agents to create a personalized family storybook enriched with both text and visuals. A Neo4j knowledge graph stores family images, memories, and comments, allowing an LLM-powered agent to generate dynamic, context-aware narratives that reflect personal histories and relationships. Additionally, a dedicated image-selection agent explores the graph to retrieve relevant photos for each generated paragraph, ensuring meaningful visual storytelling. The final output is automatically formatted and converted into a Word document, providing a beautifully structured, shareable family album that brings memories to life in a seamless, AI-assisted storytelling experience.",
        "date": "January - February 2025"
    },
    {
        "anchorId": "summoner_insight",
        "title": "Summoner-Insight: Real-Time Visualization and Prediction Assistant",
        "tags": ["react", "full_stack", "transformer", "huggingface", "js", "redux", "api", "soft_eng", "dotnet", "cs", "devops", "ux_design"],
        "summary": "A real-time visualization and prediction assistant for League of Legends, leveraging Deep Learning models for highly accurate recommendations and predictions, combined with D3.js for dynamic visualizations.",
        "description": {
            "context":"In League of Legends, players must process large amounts of information in real time to make strategic decisions. However, understanding game dynamics, predicting outcomes, and identifying optimal plays can be overwhelming, especially given the complexity of team compositions, item choices, and in-game events. Traditional analytics tools offer post-game statistics but often fail to provide actionable insights during gameplay. At the same time, recent advancements in Deep Learning, particularly Transformer-based models, have significantly improved the ability to process and interpret sequential data. These models excel at capturing long-range dependencies and contextual patterns, making them well-suited for analyzing evolving game states and predicting future scenarios with high accuracy.",
            "problem":"*How can real-time analysis and prediction in League of Legends be improved using Transformer-based models to process complex game states and provide actionable insights during gameplay with a high degree of certainty?*"},
        "date": "June 2024 - In Progress",
        "githubUrl": "https://github.com/AnalyticsLoL/SummonerInsight",
        "videoUrl": "https://www.youtube.com/embed/ZksTQdx19MU?si=YGJKUTVtG4t4aUyP",
        "websiteUrl": "http://dev.summonerinsight.com/",
        "progress": {
            "phase": "implementation",
            "status_infos": "- Basic UI designed with visualization tools and user profiles. \n - Backend API with connection to Riot API done.\n - Previous deployed but currently down due to a hardware problem.\n - Working on training a win prediction model using only start of the game players information."
        },
        "featured": true
    },
    {
        "anchorId": "math_storytelling_llm_human_comparative_study",
        "title": "Empirical Study on Teaching Math through Storytelling",
        "tags": ["empirical_methods", "mixed_methods", "aws_elastic_beanstalk", "aws_cloudfront", "aws_amplify", "r", "llm", "hci", "js", "react", "cs", "dotnet"],
        "date": "September - December 2024",
        "summary":"Study of LLM-generated vs. human-authored stories for teaching university-level math. An experiment with 16 students showed improved understanding of Gradient from AI-generated content, suggesting LLMs' potential in education.",
        "description": {
            "context":"Large Language Models (LLMs) are increasingly being integrated into educational environments, raising questions about their effectiveness as teaching tools. While previous research has primarily focused on their ability to teach mathematics to children, less attention has been given to their role in higher education. Understanding how LLM-generated educational content compares to human-authored materials is essential for assessing their potential impact on university-level learning.",
            "problem":"*How do LLM-generated stories compare to human-authored stories in enhancing university students' understanding of advanced mathematical concepts?*",
            "contribution":"This study extends prior research by evaluating the effectiveness of LLM-generated stories versus human-authored stories in teaching university-level mathematics. Through an experiment involving 16 university students, participants were exposed to two different mathematical concepts (Gradient and Bayesian Probability), with story authorship blinded to eliminate bias. Preliminary results indicate a notable improvement in understanding the gradient concept among students who read LLM-generated stories. These findings highlight the potential advantages of LLMs in teaching specific mathematical topics and suggest the need for further research into their role in higher education."
        },
        "articleUrl":"https://raw.githubusercontent.com/elnukakujo/elnukakujo.github.io/main/mywebsite/src/assets/docs/IFT6075Report.pdf",
        "githubUrl": "https://github.com/elnukakujo/Large Language Model_maths_storytelling/tree/main",
        "external_ref": [
            {
                "title": "Mathemyths: Leveraging Large Language Models to Teach Mathematical Language through Child-AI Co-Creative Storytelling",
                "url": "https://arxiv.org/abs/2402.01927"
            }
        ]
    },
    {
        "anchorId": "openai_assistant_m2_gen",
        "title": "Model assistant for the design of meta-models using OpenAI API",
        "tags": ["mde", "prompt_eng", "openai", "api", "soft_eng", "py", "pd", "llm"],
        "date": "September - December 2024",
        "summary": "Developed a Python Automated Model Assistant using OpenAI and Gemini to generate domain metamodels with Few-Shot learning, Task Decomposition, and Partial Solution Models. Achieved F1 scores of 0.90 (classes), 0.82 (attributes), and 0.79 (relations), reducing reliance on human experts.",
        "description": {
            "context":"Domain modeling is a crucial step in software and systems design, where an abstract representation of a solution domain is created to address a problem domain. Traditionally, this process requires a domain expert and an experienced modeler, iterating over multiple feedback cycles, making it time-intensive and costly. As Large Language Models (LLMs) advance, there is growing interest in automating domain model generation, reducing reliance on human intervention while maintaining high-quality results.",
            "problem":"*Can Large Language Models generate accurate domain models with minimal human intervention, reducing time and effort while maintaining high precision in class, attribute, and relationship extraction?*",
            "contribution":"This project introduces a Python Automated Model Assistant that leverages OpenAI and Gemini models to generate metamodels using Few-Shot learning, Task Decomposition, and Partial Solution Models. To our knowledge, this is the first implementation incorporating Task Decomposition and the ability to refine outputs using pre-existing partial models. Experimental results demonstrate that incorporating a 40% Partial Solution Model into the prompt significantly improves performance, achieving F1 scores of 0.90 for classes, 0.82 for attributes, and 0.79 for relationships. These findings highlight the potential of LLM-assisted domain modeling to streamline the process while maintaining strong accuracy."
        },
        "githubUrl": "https://github.com/elnukakujo/OpenAI_Assistant_M2_Gen",
        "articleUrl":"https://raw.githubusercontent.com/elnukakujo/elnukakujo.github.io/main/mywebsite/src/assets/docs/IFT6253Report.pdf",
        "external_ref": [
            {
                "title": "Automated Domain Modeling with Large Language Models: A Comparative Study",
                "url": "https://ieeexplore.ieee.org/document/10344012"
            },
            {
                "title": "Multi-step Iterative Automated Domain Modeling with Large Language Models",
                "url": "https://dl.acm.org/doi/10.1145/3652620.3687807"
            },
            {
                "title": "Matters of (Meta-)Modeling",
                "url": "https://link.springer.com/article/10.1007/s10270-006-0017-9"
            }
        ]
    },
    {
        "anchorId": "sign_language_recognition",
        "title": "Sign Language Recognition with Deep Neural Network using basic TensorFlow",
        "tags": ["py", "tf", "deepl", "cnn", "cv2", "plotly"],
        "date": "August 2024",
        "summary": "Built a TensorFlow Neural Network to recognize ASL letters from the Sign Language MNIST dataset, using OpenCV preprocessing and fully connected layers. Designed pipelines for hyperparameter tuning and optimization.",
        "description": {
            "context":"Sign Language recognition is an important area of research aimed at facilitating communication between hearing and non-hearing individuals. With the growing availability of datasets, such as the Sign Language MNIST from Kaggle, there is an opportunity to leverage deep learning techniques for automatic recognition of sign language. While more complex models, such as Convolutional Neural Networks (CNNs), are often used for this task, simpler models can also provide meaningful insights and serve as a foundation for further exploration.",
            "problem":"*How can a simple Neural Network, without CNNs, effectively recognize American Sign Language letters using the Sign Language MNIST dataset?*",
            "contribution":"This project implements a basic Neural Network using TensorFlow (not Keras) to recognize the 24 American Sign Language letters from the Sign Language MNIST dataset. The model employs dense layers and was optimized using a manually decaying learning rate, mini-batch size of 512, and two hidden layers with 85 and 84 nodes. Despite the simplicity of the model, the system achieved 81% training accuracy, 65% testing accuracy, and a 0.67 cost, demonstrating solid performance for a basic architecture. Additionally, two hypertuning pipelines were created with respective graphs to improve model optimization."
        },
        "githubUrl": "https://github.com/elnukakujo/sign_language_recognition",
        "images": [
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/sign_language_recognition/main/data/plots/20240816_172458.png",
                "description": "The evolution curve of my best training model"
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/sign_language_recognition/main/data/plots/example_caviar_tuning.png",
                "description": "Example of a caviar tuning plot"
            }
        ],
        "featured": true
    },
    {
        "anchorId": "clothing_classification",
        "title": "Clothing classification Shallow Neural Networks with NumPy",
        "tags": ["py", "np", "deepl"],
        "date": "August 2024",
        "summary":"Developed shallow neural networks in Python with NumPy to classify clothing images from the Fashion MNIST dataset. Implemented a single-layer network for binary classification and a three-layer network using ReLU, Softmax, and mini-batch gradient descent, with an optimized version using Adam.",
        "description": {
            "context":"Image classification, especially in the fashion industry, has gained significant attention for its potential applications in product recognition and recommendation systems. Leveraging datasets like Fashion MNIST provides an accessible way to explore and implement neural networks for classifying clothing images. While deep learning models such as CNNs are commonly used for such tasks, this project explores simpler, shallow neural networks to assess the performance and potential of basic architectures in achieving competitive accuracy.",
            "problem":"*How effectively can shallow neural networks classify clothing images from the Fashion MNIST dataset, and how do different network architectures impact classification accuracy?*",
            "contribution":"This project implements shallow neural networks in Python using NumPy to classify clothing images from the Fashion MNIST dataset. Three models were created: a single-layer neural network mimicking logistic regression for binary classification (achieving 97% accuracy for t-shirts and trousers after 2000 steps), a three-layer neural network using ReLU and Softmax activation functions (with 85% training accuracy and 83% testing accuracy after 10 epochs), and a three-layer network with the Adam optimizer (reaching 90% training accuracy and 87% testing accuracy after 10 epochs). These results highlight the impact of architecture and optimization techniques on performance."
        },
        "githubUrl": "https://github.com/elnukakujo/clothing_classification",
        "images": [
        {
            "imageUrl": "https://raw.githubusercontent.com/elnukakujo/clothing_classification/main/plot/binary/step_2000_train_acc_0.98.png",
            "description": "The binary classification training evolution curve"
        },
        {
            "imageUrl": "https://raw.githubusercontent.com/elnukakujo/clothing_classification/main/plot/multi_class/epoch_10_optimizer_none.png",
            "description": "The mini batch gradient descent for the multi classification"
        },
        {
            "imageUrl": "https://raw.githubusercontent.com/elnukakujo/clothing_classification/main/plot/multi_class/epoch_10_optimizer_adam.png",
            "description": "The mini batch gradient descent with Adam optimizer for the multi classification"
        }
        ]
    },
    {
        "anchorId": "movie_search_app",
        "title": "Movie search app",
        "tags": ["cs", "dotnet", "js", "react", "full_stack", "api", "soft_eng"],
        "date": "July 2024",
        "summary":"Developed a local movie search app with a React frontend and a .NET backend, integrating data from the TMDB API. Features include recommendations, search, movie and actor pages, ratings, and comments. A great learning experience in React and .NET development.",
        "description": {
            "context":"With the rise of streaming platforms, users often face difficulty in discovering new movies or series that match their interests. A movie search app can help streamline this process by offering recommendations, detailed pages for movies and series, and user reviews. Leveraging public APIs like TMDB makes it easier to provide users with accurate and up-to-date information on their favorite movies, actors, and ratings, all within a customizable interface.",
            "problem":"*How can a movie search application, powered by the TMDB API, provide an intuitive and user-friendly experience for discovering and exploring movies, series, and their associated content?*",
            "contribution":"This project created a local movie search app using React for the frontend and .NET for the backend. The app offers multiple features, including a main page with movie recommendations, a search page, dedicated pages for movies/series, actors, and commentaries, with all data sourced from the TMDB API. Although there are opportunities for further enhancement, such as filtering comments and expanding the movie list on the home page, the project effectively showcases an interactive and engaging movie exploration experience."
        },
        "githubUrl": "https://github.com/elnukakujo/movieSearchApp",
        "videoUrl": "https://www.youtube.com/embed/4F4O1xsQ4WU?si=7nBexlFtNQ4BTcMg",
        "external_ref":[
            {
                "title": "TMDB API",
                "url": "https://www.themoviedb.org/documentation/api"
            }
        ]
    },
    {
        "anchorId": "sportsai_website",
        "title": "Soccer coaching with SportsAI",
        "tags": ["plotly", "dash", "flask", "css", "data_viz", "py"],
        "date": "May - June 2024",
        "summary": "Final project for the INF8808E: Data Visualization course at Polytechnique Montréal, using a dataset from the 2020 Euro Cup. Developed a web application for soccer coaches to analyze and enhance player performance for SportsAI.",
        "description": {
            "context":"Analyzing player performance is crucial for soccer coaches to develop effective training strategies and improve team performance. By leveraging data visualization, coaches can gain valuable insights into player statistics and performance trends, ultimately leading to better decision-making. The 2020 Euro Cup dataset offers rich player data, which can be analyzed to identify key metrics and patterns that influence game outcomes.",
            "problem":"*How can data visualization techniques be applied to the 2020 Euro Cup dataset to help soccer coaches analyze and improve player performance?*",
            "contribution":"This project developed a web application for soccer coaches, leveraging the 2020 Euro Cup dataset to visualize player performance data. The tool enables coaches to analyze key performance metrics, identify trends, and make data-driven decisions to enhance player development and team strategy. The application is designed to provide actionable insights in an interactive and user-friendly interface for SportsAI."
        },
        "githubUrl": "https://github.com/elnukakujo/INF8808_DataViz_SportsAIProject",
        "websiteUrl": "https://sportsaiproject.onrender.com/",
        "images": [
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/INF8808_DataViz_SportsAIProject/main/plots/italyperformance.png",
                "description": "Stacked bar charts showcasing Italy's performance in Euro 2020 across various metrics, with an added layer indicating their positions."
            },
            {
                "imageUrl": "https://raw.githubusercontent.com/elnukakujo/INF8808_DataViz_SportsAIProject/main/plots/radarchart.png",
                "description": "Radar Chart comparing Italy and England's performance in Euro 2020 across various metrics."
            }
        ],
        "featured": true
    },
    {
        "anchorId": "drawing_with_webcam",
        "title": "Drawing with a webcam",
        "tags": ["py", "cv2", "comp_viz", "mediapipe"],
        "date": "February - June 2022",
        "summary": "Developed a real-time drawing application using Python and OpenCV under the guidance of Prof. Dr. Luis A. Leiva at the University of Luxembourg, leveraging finger position analysis for drawing actions.",
        "descriptions": [
            "With the tutoring of Prof. Dr. Luis A. LEIVA at University of Luxembourg",
            "Developed a real-time drawing application using Python and openCV",
            "Analyzed finger positions to determine drawing actions"
        ],
        "description": "Under the guidance of Prof. Dr. Luis A. Leiva at the University of Luxembourg, I developed a real-time drawing application using Python and OpenCV. The application analyzed finger positions to determine drawing actions, enabling users to interact with the system and create drawings through hand gestures. This project allowed me to explore computer vision techniques and real-time processing in a dynamic application.",
        "githubUrl": "https://github.com/elnukakujo/BSP06-Drawing-with-a-webcam",
        "external_ref":[
            {
                "title": "MediaPipe",
                "url": "https://github.com/google-ai-edge/mediapipe"
            }
        ]
    },
    {
        "anchorId": "privacy_app_figma",
        "title": "Design of a privacy app with Figma",
        "tags": ["figma", "hci"],
        "summary": "A figma prototype of an IOS privacy app, designed in the context of my HCI bachelor course at the University of Luxembourg.",
        "description": "A figma prototype of an IOS privacy app, designed in the context of my HCI bachelor course at the University of Luxembourg.",
        "date": "September - December 2021",
        "videoUrl": "https://www.youtube.com/embed/QCm1njo0ayM?si=wlDq4pp-bgf6woDg"
    },
    {
        "anchorId": "handwriting_generator",
        "title": "Handwriting Recognition with Tensorflow",
        "tags": ["deepl", "cnn", "tf", "py"],
        "date": "September 2021 - January 2022",
        "summary":"Developed a Convolutional Neural Network (CNN) in Python with TensorFlow to recognize diverse handwriting styles under the guidance of Prof. Dr. Luis A. Leiva at the University of Luxembourg, using a dataset from a separate project.",
        "description": "Under the guidance of Prof. Dr. Luis A. Leiva at the University of Luxembourg, I implemented a Convolutional Neural Network (CNN) in Python with TensorFlow to recognize diverse handwriting styles. Using a dataset from a separate project, the model was trained to replicate various handwriting styles, showcasing the power of CNNs in pattern recognition for handwritten text. This project provided valuable insights into the application of deep learning for handwriting analysis."
    },
    {
        "anchorId": "chatbot",
        "title": "Conversational Chatbot with Tensorflow",
        "tags": ["deepl", "transformer", "tf", "py"],
        "date": "February - June 2021",
        "summary": "Developed a Transformer-based chatbot in Python with TensorFlow  at the University of Luxembourg. The model, featuring encoding, Bahdanau attention, and decoding, was trained on Reddit threads for French-English translation and small talk. The project included data extraction, cleaning, model training, and chatbot interface development.",
        "description": "Under the guidance of Prof. Dr. Christoph Schommer at the University of Luxembourg, I created a transformer architecture in Python using the TensorFlow library for building a chatbot. The project involved data extraction, cleaning, online article research, and defining and training a model before creating the chatbot interface. The model consisted of three parts: an encoding layer, an Attention layer, and a decoding layer. It was trained on Reddit threads containing parent commentaries in both French and English, allowing the chatbot to engage in small talk effectively."
    },
    {
        "anchorId": "q_learning_drone",
        "title": "Q Learning for a drone in a simulated environment",
        "tags": ["q_learning", "py", "robot"],
        "date": "September 2020 - January 2021",
        "summary": "Under the guidance of Dr. Jose Luis Sanchez Lopez at the University of Luxembourg, trained a drone to navigate and avoid obstacles in a simulated AirSim environment using Python and Q-learning with a defined Q-table and rewards.",
        "description": "Under the guidance of Dr. Jose Luis Sanchez Lopez at the University of Luxembourg, I trained a drone to navigate and avoid obstacles in a simulated environment (AirSim) using Python. The drone's navigation was powered by Q-learning, where I defined a Q-table and implemented rewards to enable the drone to learn and improve its navigation strategy autonomously."
    },
    {
        "anchorId": "group_drone",
        "title": "Control of a group of drone with Unreal Engine 4 using Python",
        "tags": ["py", "ue4", "robot"],
        "date": "February - June 2020",
        "summary": "Under the guidance of Dr. Grégoire Danoy at the University of Luxembourg, developed a simulated quadrotor environment in Unreal Engine 4 with Python, enabling drones to navigate, avoid obstacles, and prevent collisions using linear algebra-based movement control.",
        "description": "Under the guidance of Dr. Gregoire Danoy at the University of Luxembourg, I created a simulated environment with quadrotors as agents using Unreal Engine 4 and Python. The project involved controlling drones to avoid obstacles and collisions, applying linear algebra concepts to ensure precise movements and enhance the drones' ability to navigate autonomously in the environment.",
        "videoUrl": "https://www.youtube.com/embed/V8-CfdUBPYI?si=k667HmWQLU5A2UTB"
    },
    {
        "anchorId": "sparki",
        "title": "Chase with Sparki",
        "tags": ["arduino", "robot"],
        "date": "September 2019 - January 2020",
        "summary": "Under the guidance of Dr. Grégoire Danoy at the University of Luxembourg, programmed Sparki robots in Sparkiduino to chase another Sparki while staying within an enclosure marked on the ground.",
        "description": "Under the guidance of Dr. Gregoire Danoy at the University of Luxembourg, I learned to work with the Sparki robot and programmed it using Sparkiduino. The task was to code Sparki to chase another Sparki while ensuring both robots stayed within an enclosure marked by ground markers. This project involved both robot control and spatial awareness programming."
    }
]